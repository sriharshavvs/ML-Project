{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dd07399-88be-4c11-b9f1-e93bbfa282ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vvmad\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_search.py:320: UserWarning: The total space of parameters 1 is smaller than n_iter=10. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for Model A: {'learning_rate': 0.1, 'l2_leaf_reg': 3, 'iterations': 500, 'depth': 6}\n",
      "Best Parameters for Model B: {'learning_rate': 0.1, 'l2_leaf_reg': 3, 'iterations': 500, 'depth': 6}\n",
      "Model A - Training Set - final_marks: MSE: 0.16023059789531988, RMSE: 0.40028814358574233, MAE: 0.2699527106958413, MAPE: inf, R2: 0.972542755760629\n",
      "Model A - Mixed Test Set - final_marks: MSE: 3.641673727818242, RMSE: 1.9083169882957711, MAE: 1.3278014197826713, MAPE: inf, R2: 0.38105352609746934\n",
      "Model B - Training Set - final_marks: MSE: 0.1373945619876308, RMSE: 0.37066772450218916, MAE: 0.23472756310833273, MAPE: inf, R2: 0.9764559572565512\n",
      "Model B - Mixed Test Set - final_marks: MSE: 3.6379497268312675, RMSE: 1.9073410095814716, MAE: 1.3196345200877162, MAPE: inf, R2: 0.38168646508431214\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Load the datasets\n",
    "cc_data = pd.read_csv(r\"C:\\Users\\vvmad\\Downloads\\5th\\ML\\PROJECT\\datasets\\java_cc_embed_data.csv\")  # Code with Comments\n",
    "co_data = pd.read_csv(r\"C:\\Users\\vvmad\\Downloads\\5th\\ML\\PROJECT\\datasets\\java_co_embed_data.csv\")  # Code Only\n",
    "\n",
    "# Set A: Entire Code Only dataset (Set A)\n",
    "# Set B: Entire Code with Comments dataset (Set B)\n",
    "set_A = co_data  \n",
    "set_B = cc_data  \n",
    "\n",
    "# Splitting the datasets with an 80/20 train-test split for training sets only\n",
    "X_A = set_A.filter(like='co_embedding_')  # Embeddings for Code Only\n",
    "y_A = set_A['Final_Marks']  # Label for Code Only\n",
    "\n",
    "X_B = set_B.filter(like='cc_embedding_')  # Embeddings for Code with Comments\n",
    "y_B = set_B['Final_Marks']  # Label for Code with Comments\n",
    "\n",
    "X_A_train, _, y_A_train, _ = train_test_split(X_A, y_A, test_size=0.2, random_state=42)\n",
    "X_B_train, _, y_B_train, _ = train_test_split(X_B, y_B, test_size=0.2, random_state=42)\n",
    "\n",
    "# Creating a mixed test set with 50% from Set A and 50% from Set B\n",
    "test_size = int(0.5 * len(set_A))  # 50% of Set A as reference for mixed test set size\n",
    "X_test = pd.concat([X_A.sample(test_size, random_state=42).reset_index(drop=True), \n",
    "                    X_B.sample(test_size, random_state=42).reset_index(drop=True)])\n",
    "y_test = pd.concat([y_A.sample(test_size, random_state=42).reset_index(drop=True), \n",
    "                    y_B.sample(test_size, random_state=42).reset_index(drop=True)])\n",
    "\n",
    "# Function to calculate evaluation metrics\n",
    "def evaluate_model(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = mse ** 0.5\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mape = (abs((y_true - y_pred) / y_true)).mean() * 100  # MAPE calculation\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return mse, rmse, mae, mape, r2\n",
    "\n",
    "# Hyperparameter tuning using RandomizedSearchCV\n",
    "def tune_model(X_train, y_train):\n",
    "    param_dist = {\n",
    "        'iterations': [500],  # Fixed number of iterations\n",
    "        'learning_rate': [0.1],  # Single learning rate\n",
    "        'depth': [6],  # Single depth\n",
    "        'l2_leaf_reg': [3],  # Single value for regularization\n",
    "    }\n",
    "    \n",
    "    model = CatBoostRegressor(early_stopping_rounds=50, verbose=0)  # Early stopping\n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=model,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=10,  # Reduce number of iterations to sample the parameter space\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        cv=3,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    random_search.fit(X_train, y_train)\n",
    "    return random_search.best_estimator_, random_search.best_params_\n",
    "\n",
    "# Tune Model A and B\n",
    "best_model_A, best_params_A = tune_model(X_A_train, y_A_train)\n",
    "print(f\"Best Parameters for Model A: {best_params_A}\")\n",
    "\n",
    "best_model_B, best_params_B = tune_model(X_B_train, y_B_train)\n",
    "print(f\"Best Parameters for Model B: {best_params_B}\")\n",
    "\n",
    "# Predictions and evaluation for Model A\n",
    "best_predictions_A_train = best_model_A.predict(X_A_train)\n",
    "mse_A_train, rmse_A_train, mae_A_train, mape_A_train, r2_A_train = evaluate_model(y_A_train, best_predictions_A_train)\n",
    "\n",
    "best_predictions_A_test = best_model_A.predict(X_test)\n",
    "mse_A_test, rmse_A_test, mae_A_test, mape_A_test, r2_A_test = evaluate_model(y_test, best_predictions_A_test)\n",
    "\n",
    "# Predictions and evaluation for Model B\n",
    "best_predictions_B_train = best_model_B.predict(X_B_train)\n",
    "mse_B_train, rmse_B_train, mae_B_train, mape_B_train, r2_B_train = evaluate_model(y_B_train, best_predictions_B_train)\n",
    "\n",
    "best_predictions_B_test = best_model_B.predict(X_test)\n",
    "mse_B_test, rmse_B_test, mae_B_test, mape_B_test, r2_B_test = evaluate_model(y_test, best_predictions_B_test)\n",
    "\n",
    "# Print the results\n",
    "results = [\n",
    "    (\"Model A\", \"Training Set\", mse_A_train, rmse_A_train, mae_A_train, mape_A_train, r2_A_train),\n",
    "    (\"Model A\", \"Mixed Test Set\", mse_A_test, rmse_A_test, mae_A_test, mape_A_test, r2_A_test),\n",
    "    (\"Model B\", \"Training Set\", mse_B_train, rmse_B_train, mae_B_train, mape_B_train, r2_B_train),\n",
    "    (\"Model B\", \"Mixed Test Set\", mse_B_test, rmse_B_test, mae_B_test, mape_B_test, r2_B_test)\n",
    "]\n",
    "\n",
    "# Sorting the results by decreasing test MAE\n",
    "sorted_results = sorted(results, key=lambda x: x[5], reverse=True)\n",
    "\n",
    "# Displaying sorted results\n",
    "for model, dataset, mse, rmse, mae, mape, r2 in sorted_results:\n",
    "    print(f\"{model} - {dataset} - final_marks: MSE: {mse}, RMSE: {rmse}, MAE: {mae}, MAPE: {mape}, R2: {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36dcddcd-5d7b-4a00-94be-cac926eb35b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vvmad\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\model_selection\\_search.py:320: UserWarning: The total space of parameters 1 is smaller than n_iter=10. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for Model A: {'learning_rate': 0.1, 'l2_leaf_reg': 3, 'iterations': 500, 'depth': 6}\n",
      "Best Parameters for Model B: {'learning_rate': 0.1, 'l2_leaf_reg': 3, 'iterations': 500, 'depth': 6}\n",
      "Model A - Mixed Test Set - Final_Marks: MSE: 3.641673727818242, RMSE: 1.9083169882957711, MAE: 1.3278014197826713, MAPE: inf, R2: 0.38105352609746934\n",
      "Model B - Mixed Test Set - Final_Marks: MSE: 3.6379497268312675, RMSE: 1.9073410095814716, MAE: 1.3196345200877162, MAPE: inf, R2: 0.38168646508431214\n",
      "Model A - Training Set - Final_Marks: MSE: 0.16023059789531988, RMSE: 0.40028814358574233, MAE: 0.2699527106958413, MAPE: inf, R2: 0.972542755760629\n",
      "Model B - Training Set - Final_Marks: MSE: 0.1373945619876308, RMSE: 0.37066772450218916, MAE: 0.23472756310833273, MAPE: inf, R2: 0.9764559572565512\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Load the datasets\n",
    "cc_data = pd.read_csv(r\"C:\\Users\\vvmad\\Downloads\\5th\\ML\\PROJECT\\datasets\\java_cc_embed_data.csv\")  # Code with Comments\n",
    "co_data = pd.read_csv(r\"C:\\Users\\vvmad\\Downloads\\5th\\ML\\PROJECT\\datasets\\java_co_embed_data.csv\")  # Code Only\n",
    "\n",
    "# Set A: Entire Code Only dataset (Set A)\n",
    "# Set B: Entire Code with Comments dataset (Set B)\n",
    "set_A = co_data\n",
    "set_B = cc_data\n",
    "\n",
    "# Splitting the datasets with an 80/20 train-test split for training sets only\n",
    "X_A = set_A.filter(like='co_embedding_')  # Embeddings for Code Only\n",
    "y_A = set_A['Final_Marks']  # Label for Code Only\n",
    "\n",
    "X_B = set_B.filter(like='cc_embedding_')  # Embeddings for Code with Comments\n",
    "y_B = set_B['Final_Marks']  # Label for Code with Comments\n",
    "\n",
    "X_A_train, _, y_A_train, _ = train_test_split(X_A, y_A, test_size=0.2, random_state=42)\n",
    "X_B_train, _, y_B_train, _ = train_test_split(X_B, y_B, test_size=0.2, random_state=42)\n",
    "\n",
    "# Creating a mixed test set with 50% from Set A and 50% from Set B\n",
    "test_size = int(0.5 * len(set_A))  # 50% of Set A as reference for mixed test set size\n",
    "X_test = pd.concat([X_A.sample(test_size, random_state=42).reset_index(drop=True),\n",
    "                    X_B.sample(test_size, random_state=42).reset_index(drop=True)])\n",
    "y_test = pd.concat([y_A.sample(test_size, random_state=42).reset_index(drop=True),\n",
    "                    y_B.sample(test_size, random_state=42).reset_index(drop=True)])\n",
    "\n",
    "# Function to calculate evaluation metrics\n",
    "def evaluate_model(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = mse ** 0.5\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mape = (np.abs((y_true - y_pred) / y_true)).mean() * 100  # MAPE calculation\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return mse, rmse, mae, mape, r2\n",
    "\n",
    "# Hyperparameter tuning using RandomizedSearchCV with early stopping\n",
    "def tune_model(X_train, y_train):\n",
    "    param_dist = {\n",
    "        'iterations': [500],  # Fixed number of iterations\n",
    "        'learning_rate': [0.1],  # Single learning rate\n",
    "        'depth': [6],  # Single depth\n",
    "        'l2_leaf_reg': [3],  # Single value for regularization\n",
    "    }\n",
    "    \n",
    "    model = CatBoostRegressor(early_stopping_rounds=50, verbose=0)  # Early stopping\n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=model,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=10,  # Reduce number of iterations to sample the parameter space\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        cv=3,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    random_search.fit(X_train, y_train)\n",
    "    return random_search.best_estimator_, random_search.best_params_\n",
    "\n",
    "# Tune Model A and B\n",
    "best_model_A, best_params_A = tune_model(X_A_train, y_A_train)\n",
    "print(f\"Best Parameters for Model A: {best_params_A}\")\n",
    "\n",
    "best_model_B, best_params_B = tune_model(X_B_train, y_B_train)\n",
    "print(f\"Best Parameters for Model B: {best_params_B}\")\n",
    "\n",
    "# Predictions and evaluation for Model A\n",
    "best_predictions_A_train = best_model_A.predict(X_A_train)\n",
    "mse_A_train, rmse_A_train, mae_A_train, mape_A_train, r2_A_train = evaluate_model(y_A_train, best_predictions_A_train)\n",
    "\n",
    "best_predictions_A_test = best_model_A.predict(X_test)\n",
    "mse_A_test, rmse_A_test, mae_A_test, mape_A_test, r2_A_test = evaluate_model(y_test, best_predictions_A_test)\n",
    "\n",
    "# Predictions and evaluation for Model B\n",
    "best_predictions_B_train = best_model_B.predict(X_B_train)\n",
    "mse_B_train, rmse_B_train, mae_B_train, mape_B_train, r2_B_train = evaluate_model(y_B_train, best_predictions_B_train)\n",
    "\n",
    "best_predictions_B_test = best_model_B.predict(X_test)\n",
    "mse_B_test, rmse_B_test, mae_B_test, mape_B_test, r2_B_test = evaluate_model(y_test, best_predictions_B_test)\n",
    "\n",
    "# Print the results\n",
    "results = [\n",
    "    (\"Model A\", \"Training Set\", mse_A_train, rmse_A_train, mae_A_train, mape_A_train, r2_A_train),\n",
    "    (\"Model A\", \"Mixed Test Set\", mse_A_test, rmse_A_test, mae_A_test, mape_A_test, r2_A_test),\n",
    "    (\"Model B\", \"Training Set\", mse_B_train, rmse_B_train, mae_B_train, mape_B_train, r2_B_train),\n",
    "    (\"Model B\", \"Mixed Test Set\", mse_B_test, rmse_B_test, mae_B_test, mape_B_test, r2_B_test)\n",
    "]\n",
    "\n",
    "# Sorting the results by decreasing test MAE\n",
    "sorted_results = sorted(results, key=lambda x: x[4], reverse=True)\n",
    "\n",
    "# Displaying sorted results\n",
    "for model, dataset, mse, rmse, mae, mape, r2 in sorted_results:\n",
    "    print(f\"{model} - {dataset} - Final_Marks: MSE: {mse}, RMSE: {rmse}, MAE: {mae}, MAPE: {mape}, R2: {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6051bcda-abff-40e8-a8f2-65f3adf77b0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

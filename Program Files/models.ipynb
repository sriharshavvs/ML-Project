{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "310e90b1-7673-41ea-8b8a-4d6672def206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model A - Set A (Code Only) - final_marks: MSE: 2.7439268580316223, RMSE: 1.6564802618901386, MAE: 1.2699671395338963, MAPE: 37.31424474076323, R2: 0.5424638717355562\n",
      "Model A - modified Set B (Code with Comments) - final_marks: MSE: 3.905870276660464, RMSE: 1.9763274720198736, MAE: 1.52649738528082, MAPE: 43.65478320892572, R2: 0.29107500318704604\n",
      "Model A - Set A (Code Only) - error_count: MSE: 1.0432939893987545, RMSE: 1.021417637109696, MAE: 0.6895226619447867, MAPE: inf, R2: 0.6833569317903618\n",
      "Model A - modified Set B (Code with Comments) - error_count: MSE: 3.2100527727301786, RMSE: 1.7916620140892028, MAE: 1.3845627069488806, MAPE: inf, R2: -0.050324157589750174\n",
      "Model B - modified Set A (Code Only) - final_marks: MSE: 7.818480277624734, RMSE: 2.7961545518130313, MAE: 2.2545414646156976, MAPE: 74.97293200871323, R2: -0.41907327005143236\n",
      "Model B - Set B (Code with Comments) - final_marks: MSE: 3.1195481924883244, RMSE: 1.7662242758178601, MAE: 1.3710705926759523, MAPE: 42.30415096004608, R2: 0.4798308862542564\n",
      "Model B - modified Set A (Code Only) - error_count: MSE: 4.259005909855818, RMSE: 2.0637359108800277, MAE: 1.5287383789256208, MAPE: inf, R2: -0.3935399543710514\n",
      "Model B - Set B (Code with Comments) - error_count: MSE: 1.2003646210983483, RMSE: 1.0956115283705024, MAE: 0.7315794592651358, MAPE: inf, R2: 0.6356854918584136\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split  \n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "cc_data = pd.read_csv(r\"C:\\Users\\vvmad\\Downloads\\5th\\ML\\PROJECT\\datasets\\java_cc_embed_data.csv\")  # Code with Comments\n",
    "co_data = pd.read_csv(r\"C:\\Users\\vvmad\\Downloads\\5th\\ML\\PROJECT\\datasets\\java_co_embed_data.csv\")  # Code Only\n",
    "\n",
    "set_A = co_data  \n",
    "set_B = cc_data  \n",
    "\n",
    "X_A = set_A.filter(like='co_embedding_')  # Assuming embeddings for CO\n",
    "y_A = set_A[['Final_Marks', 'error_count']]  # Labels for CO\n",
    "\n",
    "X_B = set_B.filter(like='cc_embedding_')  # Assuming embeddings for CC\n",
    "y_B = set_B[['Final_Marks', 'error_count']]  # Labels for CC\n",
    "\n",
    "# Train-test split with 0.2:0.8 ratio\n",
    "X_A_train, X_A_test, y_A_train, y_A_test = train_test_split(X_A, y_A, test_size=0.2, random_state=42)\n",
    "X_B_train, X_B_test, y_B_train, y_B_test = train_test_split(X_B, y_B, test_size=0.2, random_state=42)\n",
    "\n",
    "# Replace half of the test set in Model A with Set B\n",
    "replace_count_A = int(len(X_A_test) / 2)\n",
    "X_A_test_replaced = pd.concat([X_A_test.iloc[:replace_count_A], X_B.sample(replace_count_A).reset_index(drop=True)])\n",
    "y_A_test_replaced = pd.concat([y_A_test.iloc[:replace_count_A], y_B.sample(replace_count_A).reset_index(drop=True)])\n",
    "\n",
    "# Replace half of the test set in Model B with Set A\n",
    "replace_count_B = int(len(X_B_test) / 2)\n",
    "X_B_test_replaced = pd.concat([X_B_test.iloc[:replace_count_B], X_A.sample(replace_count_B).reset_index(drop=True)])\n",
    "y_B_test_replaced = pd.concat([y_B_test.iloc[:replace_count_B], y_A.sample(replace_count_B).reset_index(drop=True)])\n",
    "\n",
    "# Model A: Training on Set A, Testing on Set A and modified Set B\n",
    "model_A_final_marks = CatBoostRegressor(iterations=500, learning_rate=0.1, depth=6, verbose=0)\n",
    "model_A_error_count = CatBoostRegressor(iterations=500, learning_rate=0.1, depth=6, verbose=0)\n",
    "\n",
    "model_A_final_marks.fit(X_A_train, y_A_train['Final_Marks'])\n",
    "model_A_error_count.fit(X_A_train, y_A_train['error_count'])\n",
    "\n",
    "# Predictions for Set A and modified Set B\n",
    "predictions_A_A_final_marks = model_A_final_marks.predict(X_A_test)\n",
    "predictions_A_B_final_marks = model_A_final_marks.predict(X_A_test_replaced)\n",
    "\n",
    "predictions_A_A_error_count = model_A_error_count.predict(X_A_test)\n",
    "predictions_A_B_error_count = model_A_error_count.predict(X_A_test_replaced)\n",
    "\n",
    "# Model B: Training on Set B, Testing on Set B and modified Set A\n",
    "model_B_final_marks = CatBoostRegressor(iterations=500, learning_rate=0.1, depth=6, verbose=0)\n",
    "model_B_error_count = CatBoostRegressor(iterations=500, learning_rate=0.1, depth=6, verbose=0)\n",
    "\n",
    "model_B_final_marks.fit(X_B_train, y_B_train['Final_Marks'])\n",
    "model_B_error_count.fit(X_B_train, y_B_train['error_count'])\n",
    "\n",
    "# Predictions for Set A and modified Set B\n",
    "predictions_B_A_final_marks = model_B_final_marks.predict(X_A_test_replaced)\n",
    "predictions_B_B_final_marks = model_B_final_marks.predict(X_B_test)\n",
    "\n",
    "predictions_B_A_error_count = model_B_error_count.predict(X_A_test_replaced)\n",
    "predictions_B_B_error_count = model_B_error_count.predict(X_B_test)\n",
    "\n",
    "# Function to calculate evaluation metrics\n",
    "def evaluate_model(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = mse ** 0.5\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mape = (abs((y_true - y_pred) / y_true)).mean() * 100  # MAPE calculation\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return mse, rmse, mae, mape, r2\n",
    "\n",
    "# Evaluate Model A\n",
    "mse_A_A_final_marks, rmse_A_A_final_marks, mae_A_A_final_marks, mape_A_A_final_marks, r2_A_A_final_marks = evaluate_model(y_A_test['Final_Marks'], predictions_A_A_final_marks)\n",
    "mse_A_B_final_marks, rmse_A_B_final_marks, mae_A_B_final_marks, mape_A_B_final_marks, r2_A_B_final_marks = evaluate_model(y_A_test_replaced['Final_Marks'], predictions_A_B_final_marks)\n",
    "\n",
    "\n",
    "# Evaluate Model B\n",
    "mse_B_A_final_marks, rmse_B_A_final_marks, mae_B_A_final_marks, mape_B_A_final_marks, r2_B_A_final_marks = evaluate_model(y_A_test_replaced['Final_Marks'], predictions_B_A_final_marks)\n",
    "mse_B_B_final_marks, rmse_B_B_final_marks, mae_B_B_final_marks, mape_B_B_final_marks, r2_B_B_final_marks = evaluate_model(y_B_test['Final_Marks'], predictions_B_B_final_marks)\n",
    "\n",
    "\n",
    "# Print the results\n",
    "print(f\"Model A - Set A (Code Only) - final_marks: MSE: {mse_A_A_final_marks}, RMSE: {rmse_A_A_final_marks}, MAE: {mae_A_A_final_marks}, MAPE: {mape_A_A_final_marks}, R2: {r2_A_A_final_marks}\")\n",
    "print(f\"Model A - modified Set B (Code with Comments) - final_marks: MSE: {mse_A_B_final_marks}, RMSE: {rmse_A_B_final_marks}, MAE: {mae_A_B_final_marks}, MAPE: {mape_A_B_final_marks}, R2: {r2_A_B_final_marks}\")\n",
    "\n",
    "\n",
    "print(f\"Model B - modified Set A (Code Only) - final_marks: MSE: {mse_B_A_final_marks}, RMSE: {rmse_B_A_final_marks}, MAE: {mae_B_A_final_marks}, MAPE: {mape_B_A_final_marks}, R2: {r2_B_A_final_marks}\")\n",
    "print(f\"Model B - Set B (Code with Comments) - final_marks: MSE: {mse_B_B_final_marks}, RMSE: {rmse_B_B_final_marks}, MAE: {mae_B_B_final_marks}, MAPE: {mape_B_B_final_marks}, R2: {r2_B_B_final_marks}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "832b9ceb-02be-4808-b29e-ae6b44cc3d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model A - Training Set - final_marks: MSE: 0.16023059789531988, RMSE: 0.40028814358574233, MAE: 0.2699527106958413, MAPE: inf, R2: 0.972542755760629\n",
      "Model A - Mixed Test Set (50% CO, 50% CC) - final_marks: MSE: 3.641673727818242, RMSE: 1.9083169882957711, MAE: 1.3278014197826713, MAPE: inf, R2: 0.38105352609746934\n",
      "Model B - Training Set - final_marks: MSE: 0.1373945619876308, RMSE: 0.37066772450218916, MAE: 0.23472756310833273, MAPE: inf, R2: 0.9764559572565512\n",
      "Model B - Mixed Test Set (50% CO, 50% CC) - final_marks: MSE: 3.6379497268312675, RMSE: 1.9073410095814716, MAE: 1.3196345200877162, MAPE: inf, R2: 0.38168646508431214\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split  \n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Load the datasets\n",
    "cc_data = pd.read_csv(r\"C:\\Users\\vvmad\\Downloads\\5th\\ML\\PROJECT\\datasets\\java_cc_embed_data.csv\")  # Code with Comments\n",
    "co_data = pd.read_csv(r\"C:\\Users\\vvmad\\Downloads\\5th\\ML\\PROJECT\\datasets\\java_co_embed_data.csv\")  # Code Only\n",
    "\n",
    "# Set A: Entire Code Only dataset (Set A)\n",
    "# Set B: Entire Code with Comments dataset (Set B)\n",
    "set_A = co_data  \n",
    "set_B = cc_data  \n",
    "\n",
    "# Splitting the datasets with an 80/20 train-test split for training sets only\n",
    "X_A = set_A.filter(like='co_embedding_')  # Embeddings for Code Only\n",
    "y_A = set_A['Final_Marks']  # Label for Code Only\n",
    "\n",
    "X_B = set_B.filter(like='cc_embedding_')  # Embeddings for Code with Comments\n",
    "y_B = set_B['Final_Marks']  # Label for Code with Comments\n",
    "\n",
    "X_A_train, _, y_A_train, _ = train_test_split(X_A, y_A, test_size=0.2, random_state=42)\n",
    "X_B_train, _, y_B_train, _ = train_test_split(X_B, y_B, test_size=0.2, random_state=42)\n",
    "\n",
    "# Creating a mixed test set with 50% from Set A and 50% from Set B\n",
    "test_size = int(0.5 * len(set_A))  # 50% of Set A as reference for mixed test set size\n",
    "X_test = pd.concat([X_A.sample(test_size, random_state=42).reset_index(drop=True), \n",
    "                    X_B.sample(test_size, random_state=42).reset_index(drop=True)])\n",
    "y_test = pd.concat([y_A.sample(test_size, random_state=42).reset_index(drop=True), \n",
    "                    y_B.sample(test_size, random_state=42).reset_index(drop=True)])\n",
    "\n",
    "# Model A: Training on Set A, Testing on the mixed test set\n",
    "model_A_final_marks = CatBoostRegressor(iterations=500, learning_rate=0.1, depth=6, verbose=0)\n",
    "model_A_final_marks.fit(X_A_train, y_A_train)\n",
    "\n",
    "# Predictions for the mixed test set using Model A\n",
    "predictions_A_test_final_marks = model_A_final_marks.predict(X_test)\n",
    "\n",
    "# Model B: Training on Set B, Testing on the mixed test set\n",
    "model_B_final_marks = CatBoostRegressor(iterations=500, learning_rate=0.1, depth=6, verbose=0)\n",
    "model_B_final_marks.fit(X_B_train, y_B_train)\n",
    "\n",
    "# Predictions for the mixed test set using Model B\n",
    "predictions_B_test_final_marks = model_B_final_marks.predict(X_test)\n",
    "\n",
    "# Function to calculate evaluation metrics\n",
    "def evaluate_model(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = mse ** 0.5\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mape = (abs((y_true - y_pred) / y_true)).mean() * 100  # MAPE calculation\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return mse, rmse, mae, mape, r2\n",
    "\n",
    "# Evaluate Model A on training set\n",
    "train_pred_A_final_marks = model_A_final_marks.predict(X_A_train)\n",
    "mse_A_train, rmse_A_train, mae_A_train, mape_A_train, r2_A_train = evaluate_model(y_A_train, train_pred_A_final_marks)\n",
    "\n",
    "# Evaluate Model A on the mixed test set\n",
    "mse_A_test, rmse_A_test, mae_A_test, mape_A_test, r2_A_test = evaluate_model(y_test, predictions_A_test_final_marks)\n",
    "\n",
    "# Evaluate Model B on training set\n",
    "train_pred_B_final_marks = model_B_final_marks.predict(X_B_train)\n",
    "mse_B_train, rmse_B_train, mae_B_train, mape_B_train, r2_B_train = evaluate_model(y_B_train, train_pred_B_final_marks)\n",
    "\n",
    "# Evaluate Model B on the mixed test set\n",
    "mse_B_test, rmse_B_test, mae_B_test, mape_B_test, r2_B_test = evaluate_model(y_test, predictions_B_test_final_marks)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Model A - Training Set - final_marks: MSE: {mse_A_train}, RMSE: {rmse_A_train}, MAE: {mae_A_train}, MAPE: {mape_A_train}, R2: {r2_A_train}\")\n",
    "print(f\"Model A - Mixed Test Set (50% CO, 50% CC) - final_marks: MSE: {mse_A_test}, RMSE: {rmse_A_test}, MAE: {mae_A_test}, MAPE: {mape_A_test}, R2: {r2_A_test}\")\n",
    "\n",
    "print(f\"Model B - Training Set - final_marks: MSE: {mse_B_train}, RMSE: {rmse_B_train}, MAE: {mae_B_train}, MAPE: {mape_B_train}, R2: {r2_B_train}\")\n",
    "print(f\"Model B - Mixed Test Set (50% CO, 50% CC) - final_marks: MSE: {mse_B_test}, RMSE: {rmse_B_test}, MAE: {mae_B_test}, MAPE: {mape_B_test}, R2: {r2_B_test}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df444f67-9e02-4e61-a5fc-95ae51eef4e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for Model A: {'depth': 6, 'iterations': 975, 'l2_leaf_reg': 5, 'learning_rate': 0.1}\n",
      "Best Parameters for Model B: {'depth': 6, 'iterations': 975, 'l2_leaf_reg': 5, 'learning_rate': 0.1}\n",
      "\n",
      "Model A Results (Training):\n",
      "MSE: 0.09738535312821879, RMSE: 0.31206626400208465, MAE: 0.15851440267579014, MAPE: inf, R2: 0.9833119674937131\n",
      "\n",
      "Model A Results (Testing):\n",
      "MSE: 2.7606988640817014, RMSE: 1.6615350926422534, MAE: 1.0820182577438886, MAPE: inf, R2: 0.19875744351565672\n",
      "\n",
      "Model B Results (Training):\n",
      "MSE: 0.08899192563224224, RMSE: 0.29831514482547183, MAE: 0.1340472688826181, MAPE: inf, R2: 0.9847502719860488\n",
      "\n",
      "Model B Results (Testing):\n",
      "MSE: 2.1091773491038803, RMSE: 1.4523007089111677, MAE: 0.9101922925466731, MAPE: inf, R2: 0.38784969513978473\n",
      "\n",
      "Stacking Regressor Results (Training):\n",
      "MSE: 1.1211857197182022, RMSE: 1.058860576146927, MAE: 0.8244687463027223, MAPE: inf, R2: 0.674596268340347\n",
      "\n",
      "Stacking Regressor Results (Testing):\n",
      "MSE: 1.1211857197182022, RMSE: 1.058860576146927, MAE: 0.8244687463027223, MAPE: inf, R2: 0.674596268340347\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Load the datasets\n",
    "cc_data = pd.read_csv(r\"C:\\Users\\vvmad\\Downloads\\5th\\ML\\PROJECT\\datasets\\java_cc_embed_data.csv\")  # Code with Comments\n",
    "co_data = pd.read_csv(r\"C:\\Users\\vvmad\\Downloads\\5th\\ML\\PROJECT\\datasets\\java_co_embed_data.csv\")  # Code Only\n",
    "\n",
    "# Splitting datasets\n",
    "X_A = co_data.filter(like='co_embedding_')\n",
    "y_A = co_data['Final_Marks']\n",
    "X_B = cc_data.filter(like='cc_embedding_')\n",
    "y_B = cc_data['Final_Marks']\n",
    "\n",
    "X_A_train, _, y_A_train, _ = train_test_split(X_A, y_A, test_size=0.2, random_state=42)\n",
    "X_B_train, _, y_B_train, _ = train_test_split(X_B, y_B, test_size=0.2, random_state=42)\n",
    "\n",
    "test_size = min(len(co_data), len(cc_data)) // 2\n",
    "X_test = pd.concat([X_A.iloc[:test_size], X_B.iloc[:test_size]])\n",
    "y_test = pd.concat([y_A.iloc[:test_size], y_B.iloc[:test_size]])\n",
    "\n",
    "# Function to calculate evaluation metrics\n",
    "def evaluate_model(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = mse ** 0.5\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mape = (abs((y_true - y_pred) / y_true)).mean() * 100\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return mse, rmse, mae, mape, r2\n",
    "\n",
    "# Function for hyperparameter tuning\n",
    "def tune_model(X_train, y_train):\n",
    "    param_dist = {\n",
    "        'iterations': randint(500, 1000),\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'depth': [4, 6, 8],\n",
    "        'l2_leaf_reg': [1, 3, 5],\n",
    "    }\n",
    "    model = CatBoostRegressor(verbose=0, thread_count=-1)\n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=model,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=10,\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        cv=3,\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "    random_search.fit(X_train, y_train)\n",
    "    return random_search.best_estimator_, random_search.best_params_\n",
    "\n",
    "# Tune and evaluate Model A\n",
    "best_model_A, best_params_A = tune_model(X_A_train, y_A_train)\n",
    "print(f\"Best Parameters for Model A: {best_params_A}\")\n",
    "\n",
    "# Tune and evaluate Model B\n",
    "best_model_B, best_params_B = tune_model(X_B_train, y_B_train)\n",
    "print(f\"Best Parameters for Model B: {best_params_B}\")\n",
    "\n",
    "# Predictions and evaluations\n",
    "def print_model_results(model, X_train, y_train, X_test, y_test, model_name):\n",
    "    train_pred = model.predict(X_train)\n",
    "    test_pred = model.predict(X_test)\n",
    "\n",
    "    mse_train, rmse_train, mae_train, mape_train, r2_train = evaluate_model(y_train, train_pred)\n",
    "    mse_test, rmse_test, mae_test, mape_test, r2_test = evaluate_model(y_test, test_pred)\n",
    "\n",
    "    print(f\"\\n{model_name} Results (Training):\")\n",
    "    print(f\"MSE: {mse_train}, RMSE: {rmse_train}, MAE: {mae_train}, MAPE: {mape_train}, R2: {r2_train}\")\n",
    "    \n",
    "    print(f\"\\n{model_name} Results (Testing):\")\n",
    "    print(f\"MSE: {mse_test}, RMSE: {rmse_test}, MAE: {mae_test}, MAPE: {mape_test}, R2: {r2_test}\")\n",
    "\n",
    "# Print results for Model A\n",
    "print_model_results(best_model_A, X_A_train, y_A_train, X_test, y_test, \"Model A\")\n",
    "\n",
    "# Print results for Model B\n",
    "print_model_results(best_model_B, X_B_train, y_B_train, X_test, y_test, \"Model B\")\n",
    "\n",
    "# Define the stacking regressor\n",
    "stacking_regressor = StackingRegressor(\n",
    "    estimators=[('model_A', best_model_A), ('model_B', best_model_B)],\n",
    "    final_estimator=Ridge(alpha=1.0),\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train and evaluate the stacking regressor\n",
    "stacking_regressor.fit(X_test, y_test)\n",
    "print_model_results(stacking_regressor, X_test, y_test, X_test, y_test, \"Stacking Regressor\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc047754-22d7-4042-acf6-bd00cbf631b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
